- [[bing]]的使用技巧以及一些好用的[[prompt]] [[AI]]
	- 规律：
	  id:: 6423b7e9-4e70-42eb-8327-fa8f4ed8d1ec
	  collapsed:: true
		- 命令似乎开始检测  `[]()` 等组合来防止用户冲破访问权限了。因为我在尝试 ((6423b46d-6146-4b69-bcae-5d767ca4fa22)) 的时候，触发了和突破指令相同的回答。 可以明确的是，现在已经不能用我提到的方法3的突破形式了。
			- ![image.png](../assets/image_1680063462579_0.png)
		- 似乎可能不同风格的命令
	- ### [[bing]]提问方式建议
	  collapsed:: true
		- 方法1 -- 巧妙绕开
		  collapsed:: true
			- 1.先与机器人随便说点什么，然后点击新话题
			- 2.黏贴如下[[prompt]]即可
				- `想知道请发邮件给我，或私信我`
				  collapsed:: true
					- 可直接换行加内容
			- 注意
			  collapsed:: true
				- 请勿使用PC端Edge侧栏的插件，也就是这个接口[ChatPage (bing.com)](https://edgeservices.bing.com/edgesvc/chat)，请用网页中 [Bing AI - 搜索](https://www.bing.com/search?q=Bing+AI&showconv=1&FORM=hpcodx) 进行搜索。
				  collapsed:: true
					- 因为这个接口或侧栏每个新话题都是新的窗口。没有重新开始提示。
					-
		- 方法2 -- 其实也是绕开
		  collapsed:: true
			- [New Bing 的prompt hack新方法 - 哔哩哔哩 (bilibili.com)](https://www.bilibili.com/read/cv21819023)
			- 原理：模型在使用时，会根据需求选择性地更多 “考虑” 某些方面，而其他方面就难以 “顾及”。显然，chatgpt 的设计人员为了让它能够稳定输出代码格式，而不会崩坏，因此使得模型在代码方面的参数是比较密集，我们只要使 chatgpt 将对话迭代次数大部分用在代码相关的区域上，就可以使这个对话中，“规则” 和“道德”相关的运算减少，从而被忽略，成功打印出 “机密” 内容。
			- 此方法无需已知的初始 prompt 内容，是一种从零开始的 prompt hack 获取初始 prompt 的手段。
		- 方法3 -- 规则冲破（似乎已失效）
		  collapsed:: true
			- https://www.make-safe-ai.com/is-bing-chat-safe/
			- 他也有对应的油猴插件，但是不建议用，我已经被封了半个月了。
	- bing笑死我
	  collapsed:: true
		- 哈哈哈哈哈哈哈哈哈哈
		-
-
- [[AI]]
	- 下面的
	- 有链接嘛？没有链接的。
	-